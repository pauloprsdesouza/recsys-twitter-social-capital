{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytwitter import Api\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "import math\n",
    "from pytwitter.models import User;\n",
    "from pytwitter.models import Tweet;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = Api(bearer_token=\"AAAAAAAAAAAAAAAAAAAAAMhqlAEAAAAA4Pqzn354Z5nlkP5lKaW98vzlVlA%3D7GIA03xacVKdFYTFg7qmgvWTZThpa2FFd4SNPUqP7uPK7Xjue5\")\n",
    "\n",
    "public_tweets = api.search_tweets(query=\"bolsonaro lang:pt has:hashtags -is:retweet\", expansions=[\"referenced_tweets.id.author_id\",\"in_reply_to_user_id\",\"attachments.media_keys\",\"author_id\",\"entities.mentions.username\"], \n",
    "                                  user_fields=[\"created_at\",\"entities\",\"id\",\"location\",\"name\",\"pinned_tweet_id\",\"profile_image_url\",\"protected\",\"public_metrics\",\"url\",\"username\",\"verified\"],\n",
    "                                  tweet_fields=[\"attachments\",\"author_id\",\"context_annotations\",\"created_at\",\"entities\",\"geo\",\"in_reply_to_user_id\",\"lang\",\"public_metrics\",\"reply_settings\",\"source\"], max_results=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User's influence and reputation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(text):\n",
    "    \"float: The sentiment score between -1.0 (negative) and 1.0 (positive)\"\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Influence Calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_influence(user: User):\n",
    "    follower_count = user.public_metrics.followers_count\n",
    "\n",
    "    # Get user's tweet count and average engagement rate\n",
    "    tweets = api.get_timelines(user.id, max_results=100, tweet_fields=[\"attachments\",\"author_id\",\"context_annotations\",\"created_at\",\"entities\",\"geo\",\"in_reply_to_user_id\",\"lang\",\"public_metrics\",\"reply_settings\",\"source\"])\n",
    "    tweet_count = len(tweets.data)\n",
    "    total_engagement = 0\n",
    "    \n",
    "    for tweet in tweets.data:\n",
    "        total_engagement += tweet.public_metrics.like_count + tweet.public_metrics.retweet_count + tweet.public_metrics.quote_count + tweet.public_metrics.reply_count\n",
    "        \n",
    "    if tweet_count > 0:\n",
    "        avg_engagement_rate = total_engagement / (tweet_count * follower_count) if total_engagement > 0 and tweet_count > 0 and follower_count > 0 else 0\n",
    "    else:\n",
    "        avg_engagement_rate = 0\n",
    "\n",
    "    # Calculate influence score\n",
    "    influence_score = math.log(follower_count + 1, 10) * (avg_engagement_rate + 1)\n",
    "    \n",
    "    return influence_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reputation Calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reputation(user: User):\n",
    "    # Get user's recent mentions and replies\n",
    "    mentions = api.search_tweets(query=f\"@{user.username}\", max_results=100)\n",
    "    replies = api.search_tweets(query=f\"to:{user.username}\", max_results=100)\n",
    "\n",
    "    # Calculate reputation score based on sentiment analysis of mentions and replies\n",
    "    positive_sentiments = 0\n",
    "    negative_sentiments = 0\n",
    "    \n",
    "    for mention in mentions.data:\n",
    "        if mention.author_id != user.id:\n",
    "            sentiment = get_sentiment_score(mention.text)\n",
    "            if sentiment > 0:\n",
    "                positive_sentiments += 1\n",
    "            elif sentiment < 0:\n",
    "                negative_sentiments += 1\n",
    "                \n",
    "    for reply in replies.data:\n",
    "        if reply.author_id != user.id:\n",
    "            sentiment = get_sentiment_score(reply.text)\n",
    "            if sentiment > 0:\n",
    "                positive_sentiments += 1\n",
    "            elif sentiment < 0:\n",
    "                negative_sentiments += 1\n",
    "                \n",
    "    if (positive_sentiments + negative_sentiments) > 0:\n",
    "        reputation_score = positive_sentiments / (positive_sentiments + negative_sentiments)\n",
    "    else:\n",
    "        reputation_score = 0\n",
    "\n",
    "    # Return influence and reputation scores\n",
    "    return reputation_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def remove_urls(text):\n",
    "    \"\"\"Remove URLs from a text\"\"\"\n",
    "    return re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "def remove_mentions(text):\n",
    "    \"\"\"Remove mentions from a text\"\"\"\n",
    "    return re.sub(r\"@\\S+\", \"\", text)\n",
    "\n",
    "def remove_hashtags(text):\n",
    "    \"\"\"Remove hashtags from a text\"\"\"\n",
    "    return re.sub(r\"#\\S+\", \"\", text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"Remove punctuation from a text\"\"\"\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Tokenize a text\"\"\"\n",
    "    return word_tokenize(text, language='portuguese')\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    \"\"\"Remove stopwords from a list of tokens\"\"\"\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    return [token for token in tokens if not token in stop_words]\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    \"\"\"Lemmatize a list of tokens\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for token in tokens:\n",
    "        lemma = lemmatizer.lemmatize(token, wordnet.VERB)\n",
    "        if lemma == token:\n",
    "            lemma = lemmatizer.lemmatize(token, wordnet.NOUN)\n",
    "        if lemma == token:\n",
    "            lemma = lemmatizer.lemmatize(token, wordnet.ADJ)\n",
    "        if lemma == token:\n",
    "            lemma = lemmatizer.lemmatize(token, wordnet.ADV)\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def synonymize(tokens):\n",
    "    \"\"\"Synonymize a list of tokens\"\"\"\n",
    "    synonyms = []\n",
    "    for token in tokens:\n",
    "        synsets = wordnet.synsets(token, lang='por')\n",
    "        if synsets:\n",
    "            synset = synsets[0]\n",
    "            for lemma in synset.lemmas(lang='por'):\n",
    "                synonym = lemma.name()\n",
    "                if synonym not in synonyms and synonym != token:\n",
    "                    synonyms.append(synonym)\n",
    "    return synonyms\n",
    "\n",
    "def preprocess_tweet(text):\n",
    "    \"\"\"Preprocess a Brazilian Portuguese tweet\"\"\"\n",
    "    text = text.lower()\n",
    "    text = remove_urls(text)\n",
    "    text = remove_mentions(text)\n",
    "    text = remove_hashtags(text)\n",
    "    text = remove_punctuation(text)\n",
    "    tokens = tokenize(text)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    tokens = lemmatize(tokens)\n",
    "    tokens.extend(synonymize(tokens))\n",
    "    return tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet Social Capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "\n",
    "def get_tweet_social_capital(tweet: Tweet):\n",
    "    # Get tweet text\n",
    "    text = tweet.text\n",
    "    \n",
    "    # Get number of likes and retweets\n",
    "    likes = tweet.public_metrics.like_count\n",
    "    retweets = tweet.public_metrics.retweet_count\n",
    "    replies = tweet.public_metrics.reply_count\n",
    "    words = len(text.split())\n",
    "    hashtags = len(re.findall(r'#(\\w+)', text))\n",
    "    \n",
    "    # Get tweet creation time\n",
    "    created_at = tweet.created_at\n",
    "    created_at = datetime.datetime.strptime(created_at, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    now = datetime.datetime.utcnow()\n",
    "    age = (now - created_at).total_seconds() / 3600 # tweet age in hours\n",
    "    \n",
    "    # Calculate recency score\n",
    "    recency_score = math.exp(-0.1 * age)\n",
    "    \n",
    "    # Get URLs in tweet\n",
    "    urls = re.findall('https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+', text)\n",
    "    num_urls = len(urls)\n",
    "    \n",
    "    # Get number of emojis in tweet\n",
    "    emojis = re.findall(r'[^\\w\\s,]', text)\n",
    "    num_emojis = len(emojis)\n",
    "    \n",
    "    # Get number of photos and videos in tweet\n",
    "    num_medias = 0\n",
    "    \n",
    "    if tweet.attachments is not None and tweet.attachments.media_keys is not None:\n",
    "        for attachment in tweet.attachments.media_keys:\n",
    "            num_medias += 1\n",
    "    \n",
    "    # Calculate media score\n",
    "    media_score = 0.5 * num_medias\n",
    "    \n",
    "    # Calculate URL score\n",
    "    url_score = 0.5 * num_urls\n",
    "    \n",
    "    # Calculate emoji score\n",
    "    emoji_score = 0.5 * num_emojis\n",
    "    \n",
    "    # Calculate engagement score\n",
    "    engagement_score = likes + retweets + replies\n",
    "    \n",
    "    # Calculate social capital\n",
    "    social_capital = recency_score * (media_score + url_score + emoji_score + engagement_score + words + hashtags)\n",
    "    \n",
    "    return {'tweet': tweet, 'score': social_capital }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Capital Calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = {}\n",
    "for user in public_tweets.includes.users:\n",
    "    teste[user.id] = [calculate_influence(user), calculate_reputation(user)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'le40747700': 24.753100092618098, 'lucineianiro57': 6.31146906070576, 'maykonwilian2': 6.279055666699698, 'jornalistavitor': 5.278702875974146, 'GuimaraesLiih': 4.811849016425214, 'betobraga14': 4.2705576070370315, 'Civuca5': 4.1008624434477765, 'flordelicadezas': 3.8037166841769916, 'DiCavaletti': 3.4505540974923665, 'pripstuita': 3.3978202526278927, 'guimarques1985': 3.3658975931999717, 'JaceNordestino': 3.23587311613621, 'DesculpasDoPT': 3.122870922864435, 'PoliticaBR5': 3.0935918820472077, 'Xavierhoz07': 2.0614270026106114, 'garcia15_stela': 1.3507329164653912, 'TaniaDur1': 1.0604019886144498, 'JoseAiltonGLim2': 0.7024648543576988, 'Vandersonjrs': 0.0}\n"
     ]
    }
   ],
   "source": [
    "ranking = {}\n",
    "usersTeste = {}\n",
    "for tweet in public_tweets.data:\n",
    "    for bla in public_tweets.includes.users:\n",
    "        if(bla.id == tweet.author_id):\n",
    "            usersTeste[bla.username] = sum(teste[tweet.author_id])\n",
    "            \n",
    "    ranking[tweet.id] = get_tweet_social_capital(tweet)\n",
    "    ranking[tweet.id]['score'] += sum(teste[tweet.author_id]) \n",
    "    \n",
    "    \n",
    "rankedUsers = dict(sorted(usersTeste.items(), key=lambda item: item[1], reverse=True))\n",
    "print(rankedUsers)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.31735854610308 O bandido do Bolsonaro, depois de assassinar 7 pessoas, dentre elas uma crian√ßa de 12 anos que corria para salvar sua vida, atirou para matar policiais. Quem j√° sabia que essa gente armada iria se voltar contra as for√ßas de seguran√ßa? Satisfeitos? #policiamilitar #exercito https://t.co/trAW2KD5Ym\n",
      "53.75598989219125 O Pal√°cio do Planalto busca aliados dentro dos partidos que estiveram ao lado do ex-presidente Jair Bolsonaro (PL) na elei√ß√£o do ano passado.\n",
      "\n",
      "O objetivo √© ampliar a base no congresso, mesmo sem contar com o apoio formal dessas legendas. \n",
      "#JornalDaCultura #JC https://t.co/mz2gHncAFc\n",
      "52.96137450697559 crime da sinuca em #Sinop: Os bolsominions q assassinaram 7 pessoas ap√≥s perder na sinuca tinham passagens por roubo, viol√™ncia dom√©stica e porte ilegal de armas.\n",
      "Mesmo assim o governo Bolsonaro deu ARMAS LEGALIZADAS aos 2 criminosos.#BrasilUrgente #bolsonaro #CidadeAlerta #BBB23 https://t.co/bkUeuA0HND\n",
      "48.2397036236754 Repeteco mas atual:\n",
      "De 2019 a 2022, sob o (des)governo de jair messias bolsonaro, vivemos um tipo de Robin Hood √†s avessas: Privaram o pobre e abastaram os ricos. Eis a foto do governo do mito. \n",
      "\n",
      "#canalhas \n",
      "#Hipocritas \n",
      "#fora\n",
      "47.97377007322257 #Brasil #Pol√≠tica Julgador que desrespeita CF n√£o merece respeito nenhum!!!! √â mais que palha√ßada. Indulto de Temer vale e n√£o interessa raz√µes. Indulto de Bolsonaro prende indultado e a√≠ √© diferente? N√£o d√°. N√£o √© jur√≠dico e da raiva.\n",
      "46.42782165281177 @cacabylima @AdriianaGaucha E a facada em Bolsonaro? E o 08de janeiro? #CPMI08dejaneiro #DanielSilveiraLivre #caciquetsererelivre #andersontorreslivre\n",
      "44.499078482128745 Chico Pinheiro desce a lenha em Bolsonaro, relembra trag√©dia, cita Lula e gera pol√™mica na web\n",
      "\n",
      "Fique por dentro das not√≠cias! Siga @PoliticaBR5. Atualiza√ß√µes di√°rias.\n",
      "\n",
      "#politica #politico #politicas...\n",
      "\n",
      " Link da not√≠cia: https://t.co/tZUN520WEU\n",
      "44.25837693162325 \"Essa tend√™ncia governista √© ruim porque n√£o cria plataformas, discuss√µes. Um debate sobre propostas\" Para o #JornaldaCultura, @gesner_oliveira\n",
      " comenta busca do governo Lula em ter apoio de partidos aliados ao ex-presidente Jair Bolsonaro. https://t.co/rkr6pvZ9QQ\n",
      "43.3795677879013 @joaodamoedo Vc nem sabe oque est√° falando.\n",
      "Sou de SINOP-MT e tinha nenhum #CAC ENVOLVIDO..  ambos teria posso de arma bem antes de bolsonaro segundo seu pr√≥prio registro... e foi dado pelo @exercitooficial\n",
      "39.12694678494249 E assim mais uma vez Bandidos travestidos de \"cidad√£os de bem\", \"patriotas\", \"crist√£os\", \"pr√≥-vida\", armamentista, CAC causaram mais uma chacina tenho o Bolsonaro assassino como co-responsavel.\n",
      "\n",
      "#BolsonaroPreso https://t.co/BH0AyLFbnB\n",
      "36.628132718700556 @pedroponciobr Quando Bolsonaro n√£o foi na Bahia alagada e mandou seus ministros , quase esfolaram o homem vivo e agora? Por que est√£o no Carnaval ao inv√©s de estarem ajudando o povo #ForaLula\n",
      "35.97637668130991 @exercitooficial @jairbolsonaro  Se os generais amea√ßaram de prender Bolsonaro, e tais Generais entregou o Brasil, os Senhores ainda n√£o os prendeu por que?!Confira o v√≠deo de RIBEIRO! #TikTok https://t.co/gxprquWjMe\n",
      "33.86823637526187 @nikolas_dm Primeira dama desqualificada. Alheia ao sofrimento do povo. √â tudo que o brasileiro n√£o precisava. Governo incompetente e com minist√©rios liderados por corruptos. Quanta diferen√ßa do governo Bolsonaro. #michellepresidente\n",
      "30.522169218277316 Eu amo Olavo de Carvalho. \n",
      "Eu amo Bolsonaro.\n",
      "Amo o Brasil.\n",
      "#Olavo https://t.co/Xgobp2WYiN\n",
      "26.365819116141402 Foram 14 anos de roubalheira no governo mas os desgra√ßados s√≥ falam do Bolsonaro. Bando de fdps apoiadores de ladr√£o. #LulaGenocida\n",
      "23.207302169914616 Se o Guime colocar um do casal Bolsonaro eu fico 2 dias sem falar mal dele #BBB23\n",
      "22.476882391231932 #Meu Presidente Bolsonaro E Do Brasil üáßüá∑ N√£o Reconhe√ßo Outro https://t.co/skCT20Lr1N\n",
      "20.29009657572731 Black sendo o capit√£o do mato do #BBB23\n",
      "Servindo o casal bolsonaro GusKey.\n",
      "17.4323889424434 As dela√ß√µes premiadas s√£o um golpe do Bolsonaro para subverter os pobres! #DesculpasDoPT\n",
      "15.778117004564324 @siteptbr V√£o dizer que foi culpa da gest√£o do #bolsonaro mozo.. pra voc√™s!\n"
     ]
    }
   ],
   "source": [
    "ranked = dict(sorted(ranking.items(), key=lambda item: item[1]['score'], reverse=True))\n",
    "for tweet in ranked: \n",
    "    print(ranking[tweet]['score'], ranking[tweet]['tweet'].text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence vs Interactions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reputation vs Interactions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram Interactions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_social_capital(tweets):\n",
    "    public_tweets = api.search_tweets(query=\"stf lang:pt has:hashtags is:retweet\", expansions=[\"referenced_tweets.id.author_id\",\"in_reply_to_user_id\",\"attachments.media_keys\",\"author_id\",\"entities.mentions.username\"],\n",
    "    user_fields=[\"created_at\",\"entities\",\"id\",\"location\",\"name\",\"pinned_tweet_id\",\"profile_image_url\",\"protected\",\"public_metrics\",\"url\",\"username\",\"verified\"],\n",
    "    tweet_fields=[\"attachments\",\"author_id\",\"context_annotations\",\"created_at\",\"entities\",\"geo\",\"in_reply_to_user_id\",\"lang\",\"public_metrics\",\"reply_settings\",\"source\"], max_results=100)\n",
    "\n",
    "    api.get_followers()\n",
    "\n",
    "    public_tweets.includes.tweets\n",
    "\n",
    "#analyze_social_capital(public_tweets.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def social_capital_impact(tweet, social_connections, interactions, texts, resources, user_popularity, user_influence):\n",
    "  # extract the user, mentions, and hashtags from the tweet\n",
    "  user = tweet['user']\n",
    "  mentions = tweet['mentions']\n",
    "  hashtags = tweet['hashtags']\n",
    "  \n",
    "  # compute the number of connections the user has in the social network\n",
    "  user_connections = np.sum(social_connections[user])\n",
    "  \n",
    "  # compute the number of connections between the user and the mentions\n",
    "  mention_connections = 0\n",
    "  for mention in mentions:\n",
    "    mention_connections += social_connections[user][mention]\n",
    "  \n",
    "  # compute the number of connections between the user and the hashtags\n",
    "  hashtag_connections = 0\n",
    "  for hashtag in hashtags:\n",
    "    hashtag_connections += social_connections[user][hashtag]\n",
    "  \n",
    "  # compute the sum of the resources associated with the tweet\n",
    "  resource_sum = 0\n",
    "  for resource in resources:\n",
    "    if resource in tweet['resources']:\n",
    "      resource_sum += resources[resource]\n",
    "  \n",
    "  # compute the number of interactions for the tweet\n",
    "  interaction_sum = interactions[tweet['tweet_id']]\n",
    "  \n",
    "  # compute the text similarity between the tweet and the other texts\n",
    "  vectorizer = TfidfVectorizer()\n",
    "  tweet_text = [tweet['text']]\n",
    "  tweet_vector = vectorizer.fit_transform(tweet_text)\n",
    "  other_vectors = vectorizer.transform(texts)\n",
    "  similarity = cosine_similarity(tweet_vector, other_vectors)\n",
    "  \n",
    "  # compute the user popularity and influence factors\n",
    "  popularity_factor = user_popularity[user]\n",
    "  influence_factor = user_influence[user]\n",
    "  \n",
    "  # compute the social capital impact as the sum of mention connections, hashtag connections, resource sum, interaction sum,\n",
    "  # text similarity, popularity factor, and influence factor divided by the number of user connections\n",
    "  impact = (mention_connections + hashtag_connections + resource_sum + interaction_sum + similarity + popularity_factor + influence_factor) / user_connections\n",
    "  \n",
    "  return impact\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ab0a4bd07e653e451a64cb3a171ddec94ddedb71f86f0f21941dd76a8744c36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
